# Use these variables to run the demo with Ollama
# Make sure you have set up your local models correctly with:
#
#   ollama pull phi3
#   ollama cp phi3 gpt-4o
#
OPENAI_BASE_URL=http://localhost:11434/v1
OPENAI_API_KEY=__not_needed

# Or comment the previous variables and use these instead
# if want to use Azure OpenAI.
# Make sure you have deployed "gpt-4o" model and update the
# imports to use:
#
#   import { AzureOpenAI as OpenAI } from "openai";
#
# AZURE_OPENAI_ENDPOINT=
# AZURE_OPENAI_API_KEY=
# OPENAI_API_VERSION=2024-02-01